{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa428c9-c478-48eb-b9d5-2931a77716db",
   "metadata": {
    "vscode": {
     "languageId": "quarto"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No valid data found on page 77. Stopping.\n",
      "Scraping complete. Data saved to enforcement_actions_2023_1_to_present.csv. Total records: 1510\n"
     ]
    }
   ],
   "source": [
    "def scrape_enforcement_actions(start_month, start_year, end_page=480):\n",
    "    # Ensure the year is >= 2013\n",
    "    if start_year < 2013:\n",
    "        print(\"Year must be >= 2013. Please provide a valid year.\")\n",
    "        return\n",
    "\n",
    "    # Initialize necessary lists to store the scraped data\n",
    "    titles, dates, links, categories = [], [], [], []\n",
    "\n",
    "    base_url = 'https://oig.hhs.gov/fraud/enforcement/'\n",
    "    page_number = 1\n",
    "\n",
    "    # Get today's date for comparison\n",
    "    today = datetime.today()\n",
    "\n",
    "    while page_number <= end_page:\n",
    "        # Form the URL for the specific page\n",
    "        url = f\"{base_url}?page={page_number}\"\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        # Find all enforcement items on the current page\n",
    "        enforcement_items = soup.find_all('li', class_='usa-card card--list pep-card--minimal mobile:grid-col-12')\n",
    "\n",
    "        # If no enforcement items are found, stop the crawling process\n",
    "        if not enforcement_items:\n",
    "            print(f\"No enforcement items found on page {page_number}. Stopping.\")\n",
    "            break\n",
    "\n",
    "        # Track if any valid data is found in this page\n",
    "        valid_data_found = False\n",
    "\n",
    "        for item in enforcement_items:\n",
    "            # Extract the title, date, category, and link\n",
    "            title_tag = item.find('h2', class_='usa-card__heading')\n",
    "            date_tag = item.find('span', class_='text-base-dark padding-right-105')\n",
    "\n",
    "            # Ensure that the tags exist\n",
    "            if not title_tag or not date_tag:\n",
    "                continue\n",
    "\n",
    "            title = title_tag.get_text(strip=True)\n",
    "            date = date_tag.get_text(strip=True)\n",
    "            date_obj = datetime.strptime(date, '%B %d, %Y')\n",
    "\n",
    "            # If the date is before the start date, skip the entry\n",
    "            if date_obj < datetime(start_year, start_month, 1):\n",
    "                continue\n",
    "\n",
    "            # If we reach here, it means we have valid data\n",
    "            valid_data_found = True\n",
    "\n",
    "            # Append the data to the lists\n",
    "            titles.append(title)\n",
    "            dates.append(date)\n",
    "\n",
    "            category = item.find('li', class_='display-inline-block usa-tag text-no-lowercase text-base-darkest bg-base-lightest margin-right-1')\n",
    "            category_text = category.get_text(strip=True) if category else 'N/A'\n",
    "            categories.append(category_text)\n",
    "\n",
    "            link = item.find('a', href=True)['href']\n",
    "            full_link = f'https://oig.hhs.gov{link}'\n",
    "            links.append(full_link)\n",
    "\n",
    "        # If no valid data is found on this page, stop the scraping process\n",
    "        if not valid_data_found:\n",
    "            print(f\"No valid data found on page {page_number}. Stopping.\")\n",
    "            break\n",
    "\n",
    "        # Add delay to avoid being blocked by the server\n",
    "        time.sleep(1)\n",
    "\n",
    "        # Increment the page number for the next loop iteration\n",
    "        page_number += 1\n",
    "\n",
    "    # Creating a DataFrame with all the scraped data\n",
    "    df = pd.DataFrame({\n",
    "        'Title': titles,\n",
    "        'Date': dates,\n",
    "        'Category': categories,\n",
    "        'Link': links\n",
    "    })\n",
    "\n",
    "    # Save the DataFrame to a single CSV file named with the given year and month\n",
    "    filename = f\"enforcement_actions_{start_year}_{start_month}_to_present.csv\"\n",
    "    df.to_csv(filename, index=False)\n",
    "\n",
    "    print(f\"Scraping complete. Data saved to {filename}. Total records: {len(df)}\")\n",
    "\n",
    "scrape_enforcement_actions(1, 2023, end_page=480)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4a9cd6-f495-4580-873b-b5a75dfe3cb3",
   "metadata": {
    "vscode": {
     "languageId": "quarto"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No valid data found on page 77. Stopping.\n",
      "Scraping complete. Data saved to enforcement_actions_2023_1_to_present.csv. Total records: 1510\n"
     ]
    }
   ],
   "source": [
    "def scrape_enforcement_actions(start_month, start_year, end_page=480):\n",
    "    if start_year < 2013:\n",
    "        print(\"Year must be >= 2013. Please provide a valid year.\")\n",
    "        return\n",
    "\n",
    "    titles, dates, links, categories = [], [], [], []\n",
    "\n",
    "    base_url = \"https://oig.hhs.gov/fraud/enforcement/\"\n",
    "    page_number = 1\n",
    "\n",
    "    today = datetime.today()\n",
    "\n",
    "    while page_number <= end_page:\n",
    "        url = f\"{base_url}?page={page_number}\"\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "        enforcement_items = soup.find_all(\n",
    "            \"li\", class_=\"usa-card card--list pep-card--minimal mobile:grid-col-12\"\n",
    "        )\n",
    "\n",
    "        if not enforcement_items:\n",
    "            print(f\"No enforcement items found on page {page_number}. Stopping.\")\n",
    "            break\n",
    "\n",
    "        valid_data_found = False\n",
    "\n",
    "        for item in enforcement_items:\n",
    "            title_tag = item.find(\"h2\", class_=\"usa-card__heading\")\n",
    "            date_tag = item.find(\"span\", class_=\"text-base-dark padding-right-105\")\n",
    "\n",
    "            if not title_tag or not date_tag:\n",
    "                continue\n",
    "\n",
    "            title = title_tag.get_text(strip=True)\n",
    "            date = date_tag.get_text(strip=True)\n",
    "            date_obj = datetime.strptime(date, \"%B %d, %Y\")\n",
    "\n",
    "            if date_obj < datetime(start_year, start_month, 1):\n",
    "                continue\n",
    "\n",
    "            valid_data_found = True\n",
    "\n",
    "            titles.append(title)\n",
    "            dates.append(date)\n",
    "\n",
    "            category = item.find(\n",
    "                \"li\",\n",
    "                class_=\"display-inline-block usa-tag text-no-lowercase text-base-darkest bg-base-lightest margin-right-1\",\n",
    "            )\n",
    "            category_text = category.get_text(strip=True) if category else \"N/A\"\n",
    "            categories.append(category_text)\n",
    "\n",
    "            link = item.find(\"a\", href=True)[\"href\"]\n",
    "            full_link = f\"https://oig.hhs.gov{link}\"\n",
    "            links.append(full_link)\n",
    "\n",
    "        if not valid_data_found:\n",
    "            print(f\"No valid data found on page {page_number}. Stopping.\")\n",
    "            break\n",
    "\n",
    "        time.sleep(1)\n",
    "\n",
    "        page_number += 1\n",
    "\n",
    "    df = pd.DataFrame(\n",
    "        {\"Title\": titles, \"Date\": dates, \"Category\": categories, \"Link\": links}\n",
    "    )\n",
    "\n",
    "    filename = f\"enforcement_actions_{start_year}_{start_month}_to_present.csv\"\n",
    "    df.to_csv(filename, index=False)\n",
    "\n",
    "    print(f\"Scraping complete. Data saved to {filename}. Total records: {len(df)}\")\n",
    "\n",
    "\n",
    "scrape_enforcement_actions(1, 2023, end_page=480)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
