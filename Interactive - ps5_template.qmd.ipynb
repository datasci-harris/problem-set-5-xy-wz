{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connected to base (Python 3.11.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44953d43-33f9-47bd-8d27-f0186ce1eb24",
   "metadata": {
    "vscode": {
     "languageId": "quarto"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Title              Date  \\\n",
      "0  Former Arlington Resident Sentenced To Prison ...  November 7, 2024   \n",
      "1  Paroled Felon Sentenced To Six Years For Fraud...  November 7, 2024   \n",
      "2  Former Licensed Counselor Sentenced For Defrau...  November 6, 2024   \n",
      "3  Macomb County Doctor And Pharmacist Agree To P...  November 4, 2024   \n",
      "4  Rocky Hill Pharmacy And Its Owners Indicted Fo...  November 4, 2024   \n",
      "\n",
      "                     Category  \\\n",
      "0  Criminal and Civil Actions   \n",
      "1  Criminal and Civil Actions   \n",
      "2  Criminal and Civil Actions   \n",
      "3  Criminal and Civil Actions   \n",
      "4  Criminal and Civil Actions   \n",
      "\n",
      "                                                Link  \n",
      "0  https://oig.hhs.gov/fraud/enforcement/former-a...  \n",
      "1  https://oig.hhs.gov/fraud/enforcement/paroled-...  \n",
      "2  https://oig.hhs.gov/fraud/enforcement/former-l...  \n",
      "3  https://oig.hhs.gov/fraud/enforcement/macomb-c...  \n",
      "4  https://oig.hhs.gov/fraud/enforcement/rocky-hi...  \n",
      "                                               Title              Date  \\\n",
      "0  Former Arlington Resident Sentenced To Prison ...  November 7, 2024   \n",
      "1  Paroled Felon Sentenced To Six Years For Fraud...  November 7, 2024   \n",
      "2  Former Licensed Counselor Sentenced For Defrau...  November 6, 2024   \n",
      "3  Macomb County Doctor And Pharmacist Agree To P...  November 4, 2024   \n",
      "4  Rocky Hill Pharmacy And Its Owners Indicted Fo...  November 4, 2024   \n",
      "\n",
      "                     Category  \\\n",
      "0  Criminal and Civil Actions   \n",
      "1  Criminal and Civil Actions   \n",
      "2  Criminal and Civil Actions   \n",
      "3  Criminal and Civil Actions   \n",
      "4  Criminal and Civil Actions   \n",
      "\n",
      "                                                Link  \\\n",
      "0  https://oig.hhs.gov/fraud/enforcement/former-a...   \n",
      "1  https://oig.hhs.gov/fraud/enforcement/paroled-...   \n",
      "2  https://oig.hhs.gov/fraud/enforcement/former-l...   \n",
      "3  https://oig.hhs.gov/fraud/enforcement/macomb-c...   \n",
      "4  https://oig.hhs.gov/fraud/enforcement/rocky-hi...   \n",
      "\n",
      "                                              Agency  \n",
      "0  U.S. Attorney's Office, Eastern District of Vi...  \n",
      "1  U.S. Attorney's Office, Middle District of Flo...  \n",
      "2  U.S. Attorney's Office, Western District of Texas  \n",
      "3  U.S. Attorney's Office, Eastern District of Mi...  \n",
      "4  U.S. Attorney's Office, Eastern District of Te...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import altair as alt\n",
    "import time\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "alt.renderers.enable(\"png\")\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "url = 'https://oig.hhs.gov/fraud/enforcement/'\n",
    "response = requests.get(url)\n",
    "\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "titles = []\n",
    "dates = []\n",
    "links = []\n",
    "categories = []\n",
    "\n",
    "enforcement_items = soup.find_all('li', class_='usa-card card--list pep-card--minimal mobile:grid-col-12')\n",
    "\n",
    "for item in enforcement_items:\n",
    "    title_tag = item.find('h2', class_='usa-card__heading')\n",
    "    title = title_tag.get_text(strip=True)\n",
    "    titles.append(title)\n",
    "\n",
    "    date_tag = item.find('span', class_='text-base-dark padding-right-105')\n",
    "    date = date_tag.get_text(strip=True) \n",
    "    dates.append(date)\n",
    "\n",
    "    category_tag = item.find('li', class_='display-inline-block usa-tag text-no-lowercase text-base-darkest bg-base-lightest margin-right-1')\n",
    "    category = category_tag.get_text(strip=True)\n",
    "    categories.append(category)\n",
    "\n",
    "    link_tag = title_tag.find('a', href=True) \n",
    "    link = link_tag['href'] if link_tag else 'N/A'\n",
    "    if not link.startswith('http'):\n",
    "        full_link = f'https://oig.hhs.gov{link}'\n",
    "    else:\n",
    "        full_link = link\n",
    "    links.append(full_link)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'Title': titles,\n",
    "    'Date': dates,\n",
    "    'Category': categories,\n",
    "    'Link': links\n",
    "})\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "\n",
    "import time\n",
    "\n",
    "agencies = []\n",
    "\n",
    "for full_link in links:\n",
    "    action_response = requests.get(full_link)\n",
    "    action_response.raise_for_status()\n",
    "    action_soup = BeautifulSoup(action_response.text, 'html.parser')\n",
    "\n",
    "    agency_tag = action_soup.find('span', string='Agency:')\n",
    "    if agency_tag:\n",
    "        agency = agency_tag.find_parent('li').get_text(\n",
    "            strip=True).replace('Agency:', '').strip()\n",
    "    else:\n",
    "        agency = 'N/A'\n",
    "\n",
    "    agencies.append(agency)\n",
    "\n",
    "    time.sleep(1)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'Title': titles,\n",
    "    'Date': dates,\n",
    "    'Category': categories,\n",
    "    'Link': links,\n",
    "    'Agency': agencies\n",
    "})\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01aa691b-7082-4aa9-8aec-fe2c603265c8",
   "metadata": {
    "vscode": {
     "languageId": "quarto"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Title              Date  \\\n",
      "0  Former Arlington Resident Sentenced To Prison ...  November 7, 2024   \n",
      "1  Paroled Felon Sentenced To Six Years For Fraud...  November 7, 2024   \n",
      "2  Former Licensed Counselor Sentenced For Defrau...  November 6, 2024   \n",
      "3  Macomb County Doctor And Pharmacist Agree To P...  November 4, 2024   \n",
      "4  Rocky Hill Pharmacy And Its Owners Indicted Fo...  November 4, 2024   \n",
      "\n",
      "                     Category  \\\n",
      "0  Criminal and Civil Actions   \n",
      "1  Criminal and Civil Actions   \n",
      "2  Criminal and Civil Actions   \n",
      "3  Criminal and Civil Actions   \n",
      "4  Criminal and Civil Actions   \n",
      "\n",
      "                                                Link  \\\n",
      "0  https://oig.hhs.gov/fraud/enforcement/former-a...   \n",
      "1  https://oig.hhs.gov/fraud/enforcement/paroled-...   \n",
      "2  https://oig.hhs.gov/fraud/enforcement/former-l...   \n",
      "3  https://oig.hhs.gov/fraud/enforcement/macomb-c...   \n",
      "4  https://oig.hhs.gov/fraud/enforcement/rocky-hi...   \n",
      "\n",
      "                                              Agency  \n",
      "0  U.S. Attorney's Office, Eastern District of Vi...  \n",
      "1  U.S. Attorney's Office, Middle District of Flo...  \n",
      "2  U.S. Attorney's Office, Western District of Texas  \n",
      "3  U.S. Attorney's Office, Eastern District of Mi...  \n",
      "4  U.S. Attorney's Office, Eastern District of Te...  \n",
      "Total enforcement actions collected: 20\n",
      "Earliest enforcement action: Title       St. Louis County Woman Accused Of $3 Million H...\n",
      "Date                                         November 1, 2024\n",
      "Category                           Criminal and Civil Actions\n",
      "Link        https://oig.hhs.gov/fraud/enforcement/st-louis...\n",
      "Agency      U.S. Attorney's Office, Eastern District of Mi...\n",
      "Name: 7, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "def scrape_enforcement_actions(start_month, start_year):\n",
    "    # 1. Input Validation\n",
    "    if start_year < 2013:\n",
    "        print(\"Year must be >= 2013\")\n",
    "        return\n",
    "\n",
    "    # 2. Initialization\n",
    "    enforcement_data = pd.DataFrame(columns=['Title', 'Date', 'Category', 'Link', 'Agency'])\n",
    "    current_date = datetime.now()\n",
    "    current_page = 1\n",
    "    continue_scraping = True\n",
    "\n",
    "    # 3. Page Scraping Loop\n",
    "    while continue_scraping:\n",
    "        # 4. Construct URL for the Main Page\n",
    "        if current_page == 1:\n",
    "            url = \"https://oig.hhs.gov/fraud/enforcement/\"\n",
    "        else:\n",
    "            url = f\"https://oig.hhs.gov/fraud/enforcement/?page={current_page}\"\n",
    "\n",
    "        # 5. Fetch Page Content\n",
    "        response = requests.get(url)\n",
    "        if response.status_code != 200:\n",
    "            print(f\"Failed to retrieve page {current_page}\")\n",
    "            break\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        # 6. Extract Enforcement Actions\n",
    "        enforcement_items = soup.find_all('li', class_='usa-card card--list pep-card--minimal mobile:grid-col-12')\n",
    "        if not enforcement_items:\n",
    "            # No more items to scrape, stop the loop\n",
    "            continue_scraping = False\n",
    "            break\n",
    "\n",
    "        for item in enforcement_items:\n",
    "            title_tag = item.find('h2', class_='usa-card__heading')\n",
    "            title = title_tag.get_text(strip=True) if title_tag else 'N/A'\n",
    "\n",
    "            date_tag = item.find('span', class_='text-base-dark padding-right-105')\n",
    "            date = date_tag.get_text(strip=True) if date_tag else 'N/A'\n",
    "\n",
    "            category_tag = item.find('li', class_='display-inline-block usa-tag text-no-lowercase text-base-darkest bg-base-lightest margin-right-1')\n",
    "            category = category_tag.get_text(strip=True) if category_tag else 'N/A'\n",
    "\n",
    "            link_tag = title_tag.find('a', href=True) if title_tag else None\n",
    "            link = link_tag['href'] if link_tag else 'N/A'\n",
    "            if link != 'N/A' and not link.startswith('http'):\n",
    "                link = f'https://oig.hhs.gov{link}'\n",
    "\n",
    "            # 7. Deep Scraping of Detailed Information\n",
    "            if link != 'N/A':\n",
    "                action_response = requests.get(link)\n",
    "                if action_response.status_code == 200:\n",
    "                    action_soup = BeautifulSoup(action_response.text, 'html.parser')\n",
    "                    agency_tag = action_soup.find('span', string='Agency:')\n",
    "                    if agency_tag:\n",
    "                        agency = agency_tag.find_parent('li').get_text(strip=True).replace('Agency:', '').strip()\n",
    "                    else:\n",
    "                        agency = 'N/A'\n",
    "                else:\n",
    "                    agency = 'N/A'\n",
    "            else:\n",
    "                agency = 'N/A'\n",
    "\n",
    "            # Add data to the DataFrame\n",
    "            enforcement_data = pd.concat([enforcement_data, pd.DataFrame([{\n",
    "                'Title': title,\n",
    "                'Date': date,\n",
    "                'Category': category,\n",
    "                'Link': link,\n",
    "                'Agency': agency\n",
    "            }])], ignore_index=True)\n",
    "\n",
    "        # 8. Check for Next Page\n",
    "        next_page_tag = soup.find('a', class_='next-page-link')\n",
    "        if next_page_tag:\n",
    "            current_page += 1\n",
    "        else:\n",
    "            continue_scraping = False\n",
    "\n",
    "        # 9. Add Delay Between Requests\n",
    "        time.sleep(1)\n",
    "\n",
    "    # 10. Save Data to CSV\n",
    "    filename = f\"enforcement_actions_{start_year}_{start_month}.csv\"\n",
    "    enforcement_data.to_csv(filename, index=False)\n",
    "    \n",
    "    # Return the DataFrame for analysis\n",
    "    return enforcement_data\n",
    "\n",
    "# Run the function to collect enforcement actions since January 2023\n",
    "df = scrape_enforcement_actions(1, 2023)\n",
    "\n",
    "# Display the result\n",
    "print(df.head())\n",
    "\n",
    "# Display details about the number of enforcement actions and the earliest action\n",
    "total_actions = len(df)\n",
    "early_action = df.iloc[df['Date'].idxmin()]\n",
    "print(f\"Total enforcement actions collected: {total_actions}\")\n",
    "print(f\"Earliest enforcement action: {early_action}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9823b5e7-6e4e-47aa-97cc-26d1a654be83",
   "metadata": {
    "vscode": {
     "languageId": "quarto"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Title              Date  \\\n",
      "0  Former Arlington Resident Sentenced To Prison ...  November 7, 2024   \n",
      "1  Paroled Felon Sentenced To Six Years For Fraud...  November 7, 2024   \n",
      "2  Former Licensed Counselor Sentenced For Defrau...  November 6, 2024   \n",
      "3  Macomb County Doctor And Pharmacist Agree To P...  November 4, 2024   \n",
      "4  Rocky Hill Pharmacy And Its Owners Indicted Fo...  November 4, 2024   \n",
      "\n",
      "                     Category  \\\n",
      "0  Criminal and Civil Actions   \n",
      "1  Criminal and Civil Actions   \n",
      "2  Criminal and Civil Actions   \n",
      "3  Criminal and Civil Actions   \n",
      "4  Criminal and Civil Actions   \n",
      "\n",
      "                                                Link  \\\n",
      "0  https://oig.hhs.gov/fraud/enforcement/former-a...   \n",
      "1  https://oig.hhs.gov/fraud/enforcement/paroled-...   \n",
      "2  https://oig.hhs.gov/fraud/enforcement/former-l...   \n",
      "3  https://oig.hhs.gov/fraud/enforcement/macomb-c...   \n",
      "4  https://oig.hhs.gov/fraud/enforcement/rocky-hi...   \n",
      "\n",
      "                                              Agency  \n",
      "0  U.S. Attorney's Office, Eastern District of Vi...  \n",
      "1  U.S. Attorney's Office, Middle District of Flo...  \n",
      "2  U.S. Attorney's Office, Western District of Texas  \n",
      "3  U.S. Attorney's Office, Eastern District of Mi...  \n",
      "4  U.S. Attorney's Office, Eastern District of Te...  \n",
      "Total enforcement actions collected: 20\n",
      "Earliest enforcement action: Title       St. Louis County Woman Accused Of $3 Million H...\n",
      "Date                                         November 1, 2024\n",
      "Category                           Criminal and Civil Actions\n",
      "Link        https://oig.hhs.gov/fraud/enforcement/st-louis...\n",
      "Agency      U.S. Attorney's Office, Eastern District of Mi...\n",
      "Name: 7, dtype: object\n"
     ]
    }
   ],
   "source": [
    "def scrape_enforcement_actions(start_month, start_year):\n",
    "    # 1. Input Validation\n",
    "    if start_year < 2013:\n",
    "        print(\"Year must be >= 2013\")\n",
    "        return\n",
    "\n",
    "    # 2. Initialization\n",
    "    enforcement_data = pd.DataFrame(columns=['Title', 'Date', 'Category', 'Link', 'Agency'])\n",
    "    current_date = datetime.now()\n",
    "    current_page = 1\n",
    "    continue_scraping = True\n",
    "\n",
    "    # 3. Page Scraping Loop\n",
    "    while continue_scraping:\n",
    "        # 4. Construct URL for the Main Page\n",
    "        if current_page == 1:\n",
    "            url = \"https://oig.hhs.gov/fraud/enforcement/\"\n",
    "        else:\n",
    "            url = f\"https://oig.hhs.gov/fraud/enforcement/?page={current_page}\"\n",
    "\n",
    "        # 5. Fetch Page Content\n",
    "        response = requests.get(url)\n",
    "        if response.status_code != 200:\n",
    "            print(f\"Failed to retrieve page {current_page}\")\n",
    "            break\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        # 6. Extract Enforcement Actions\n",
    "        enforcement_items = soup.find_all('li', class_='usa-card card--list pep-card--minimal mobile:grid-col-12')\n",
    "        if not enforcement_items:\n",
    "            # No more items to scrape, stop the loop\n",
    "            continue_scraping = False\n",
    "            break\n",
    "\n",
    "        for item in enforcement_items:\n",
    "            title_tag = item.find('h2', class_='usa-card__heading')\n",
    "            title = title_tag.get_text(strip=True) if title_tag else 'N/A'\n",
    "\n",
    "            date_tag = item.find('span', class_='text-base-dark padding-right-105')\n",
    "            date = date_tag.get_text(strip=True) if date_tag else 'N/A'\n",
    "\n",
    "            category_tag = item.find('li', class_='display-inline-block usa-tag text-no-lowercase text-base-darkest bg-base-lightest margin-right-1')\n",
    "            category = category_tag.get_text(strip=True) if category_tag else 'N/A'\n",
    "\n",
    "            link_tag = title_tag.find('a', href=True) if title_tag else None\n",
    "            link = link_tag['href'] if link_tag else 'N/A'\n",
    "            if link != 'N/A' and not link.startswith('http'):\n",
    "                link = f'https://oig.hhs.gov{link}'\n",
    "\n",
    "            # 7. Deep Scraping of Detailed Information\n",
    "            if link != 'N/A':\n",
    "                action_response = requests.get(link)\n",
    "                if action_response.status_code == 200:\n",
    "                    action_soup = BeautifulSoup(action_response.text, 'html.parser')\n",
    "                    agency_tag = action_soup.find('span', string='Agency:')\n",
    "                    if agency_tag:\n",
    "                        agency = agency_tag.find_parent('li').get_text(strip=True).replace('Agency:', '').strip()\n",
    "                    else:\n",
    "                        agency = 'N/A'\n",
    "                else:\n",
    "                    agency = 'N/A'\n",
    "            else:\n",
    "                agency = 'N/A'\n",
    "\n",
    "            # Add data to the DataFrame\n",
    "            enforcement_data = pd.concat([enforcement_data, pd.DataFrame([{\n",
    "                'Title': title,\n",
    "                'Date': date,\n",
    "                'Category': category,\n",
    "                'Link': link,\n",
    "                'Agency': agency\n",
    "            }])], ignore_index=True)\n",
    "\n",
    "        # 8. Check for Next Page\n",
    "        next_page_tag = soup.find('a', class_='next-page-link')\n",
    "        if next_page_tag:\n",
    "            current_page += 1\n",
    "        else:\n",
    "            continue_scraping = False\n",
    "\n",
    "        # 9. Add Delay Between Requests\n",
    "        time.sleep(1)\n",
    "\n",
    "    # 10. Save Data to CSV\n",
    "    filename = f\"enforcement_actions_{start_year}_{start_month}.csv\"\n",
    "    enforcement_data.to_csv(filename, index=False)\n",
    "    \n",
    "    # Return the DataFrame for analysis\n",
    "    return enforcement_data\n",
    "\n",
    "# Run the function to collect enforcement actions since January 2023\n",
    "df = scrape_enforcement_actions(1, 2023)\n",
    "\n",
    "# Display the result\n",
    "print(df.head())\n",
    "\n",
    "# Display details about the number of enforcement actions and the earliest action\n",
    "total_actions = len(df)\n",
    "early_action = df.iloc[df['Date'].idxmin()]\n",
    "print(f\"Total enforcement actions collected: {total_actions}\")\n",
    "print(f\"Earliest enforcement action: {early_action}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ad7842-cd4f-405e-a023-c7b6a2710946",
   "metadata": {
    "vscode": {
     "languageId": "quarto"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Title              Date  \\\n",
      "0  Former Arlington Resident Sentenced To Prison ...  November 7, 2024   \n",
      "1  Paroled Felon Sentenced To Six Years For Fraud...  November 7, 2024   \n",
      "2  Former Licensed Counselor Sentenced For Defrau...  November 6, 2024   \n",
      "3  Macomb County Doctor And Pharmacist Agree To P...  November 4, 2024   \n",
      "4  Rocky Hill Pharmacy And Its Owners Indicted Fo...  November 4, 2024   \n",
      "\n",
      "                     Category  \\\n",
      "0  Criminal and Civil Actions   \n",
      "1  Criminal and Civil Actions   \n",
      "2  Criminal and Civil Actions   \n",
      "3  Criminal and Civil Actions   \n",
      "4  Criminal and Civil Actions   \n",
      "\n",
      "                                                Link  \\\n",
      "0  https://oig.hhs.gov/fraud/enforcement/former-a...   \n",
      "1  https://oig.hhs.gov/fraud/enforcement/paroled-...   \n",
      "2  https://oig.hhs.gov/fraud/enforcement/former-l...   \n",
      "3  https://oig.hhs.gov/fraud/enforcement/macomb-c...   \n",
      "4  https://oig.hhs.gov/fraud/enforcement/rocky-hi...   \n",
      "\n",
      "                                              Agency  \n",
      "0  U.S. Attorney's Office, Eastern District of Vi...  \n",
      "1  U.S. Attorney's Office, Middle District of Flo...  \n",
      "2  U.S. Attorney's Office, Western District of Texas  \n",
      "3  U.S. Attorney's Office, Eastern District of Mi...  \n",
      "4  U.S. Attorney's Office, Eastern District of Te...  \n",
      "Total enforcement actions collected: 20\n",
      "Earliest enforcement action: Title       St. Louis County Woman Accused Of $3 Million H...\n",
      "Date                                         November 1, 2024\n",
      "Category                           Criminal and Civil Actions\n",
      "Link        https://oig.hhs.gov/fraud/enforcement/st-louis...\n",
      "Agency      U.S. Attorney's Office, Eastern District of Mi...\n",
      "Name: 7, dtype: object\n"
     ]
    }
   ],
   "source": [
    "def scrape_enforcement_actions(start_month, start_year):\n",
    "    if start_year < 2013:\n",
    "        print(\"Year must be >= 2013\")\n",
    "        return\n",
    "\n",
    "    enforcement_data = pd.DataFrame(columns=['Title', 'Date', 'Category', 'Link', 'Agency'])\n",
    "    current_date = datetime.now()\n",
    "    current_page = 1\n",
    "    continue_scraping = True\n",
    "\n",
    "    while continue_scraping:\n",
    "        if current_page == 1:\n",
    "            url = \"https://oig.hhs.gov/fraud/enforcement/\"\n",
    "        else:\n",
    "            url = f\"https://oig.hhs.gov/fraud/enforcement/?page={current_page}\"\n",
    "\n",
    "        response = requests.get(url)\n",
    "        if response.status_code != 200:\n",
    "            print(f\"Failed to retrieve page {current_page}\")\n",
    "            break\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        enforcement_items = soup.find_all('li', class_='usa-card card--list pep-card--minimal mobile:grid-col-12')\n",
    "        if not enforcement_items:\n",
    "            continue_scraping = False\n",
    "            break\n",
    "\n",
    "        for item in enforcement_items:\n",
    "            title_tag = item.find('h2', class_='usa-card__heading')\n",
    "            title = title_tag.get_text(strip=True) if title_tag else 'N/A'\n",
    "\n",
    "            date_tag = item.find('span', class_='text-base-dark padding-right-105')\n",
    "            date = date_tag.get_text(strip=True) if date_tag else 'N/A'\n",
    "\n",
    "            category_tag = item.find('li', class_='display-inline-block usa-tag text-no-lowercase text-base-darkest bg-base-lightest margin-right-1')\n",
    "            category = category_tag.get_text(strip=True) if category_tag else 'N/A'\n",
    "\n",
    "            link_tag = title_tag.find('a', href=True) if title_tag else None\n",
    "            link = link_tag['href'] if link_tag else 'N/A'\n",
    "            if link != 'N/A' and not link.startswith('http'):\n",
    "                link = f'https://oig.hhs.gov{link}'\n",
    "\n",
    "            if link != 'N/A':\n",
    "                action_response = requests.get(link)\n",
    "                if action_response.status_code == 200:\n",
    "                    action_soup = BeautifulSoup(action_response.text, 'html.parser')\n",
    "                    agency_tag = action_soup.find('span', string='Agency:')\n",
    "                    if agency_tag:\n",
    "                        agency = agency_tag.find_parent('li').get_text(strip=True).replace('Agency:', '').strip()\n",
    "                    else:\n",
    "                        agency = 'N/A'\n",
    "                else:\n",
    "                    agency = 'N/A'\n",
    "            else:\n",
    "                agency = 'N/A'\n",
    "\n",
    "            enforcement_data = pd.concat([enforcement_data, pd.DataFrame([{\n",
    "                'Title': title,\n",
    "                'Date': date,\n",
    "                'Category': category,\n",
    "                'Link': link,\n",
    "                'Agency': agency\n",
    "            }])], ignore_index=True)\n",
    "\n",
    "        next_page_tag = soup.find('a', class_='next-page-link')\n",
    "        if next_page_tag:\n",
    "            current_page += 1\n",
    "        else:\n",
    "            continue_scraping = False\n",
    "\n",
    "        time.sleep(1)\n",
    "\n",
    "    filename = f\"enforcement_actions_{start_year}_{start_month}.csv\"\n",
    "    enforcement_data.to_csv(filename, index=False)\n",
    "    \n",
    "    return enforcement_data\n",
    "\n",
    "df = scrape_enforcement_actions(1, 2023)\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "total_actions = len(df)\n",
    "early_action = df.iloc[df['Date'].idxmin()]\n",
    "print(f\"Total enforcement actions collected: {total_actions}\")\n",
    "print(f\"Earliest enforcement action: {early_action}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
